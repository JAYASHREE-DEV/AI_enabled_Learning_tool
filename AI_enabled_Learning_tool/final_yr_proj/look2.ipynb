{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c34094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from PyQt5.QtWidgets import *\n",
    "from PyQt5.QtGui import *\n",
    "from PyQt5.QtMultimedia import *\n",
    "from PyQt5.QtMultimediaWidgets import *\n",
    "from PyQt5.QtCore import *\n",
    "#ForQuiz\n",
    "\n",
    "import sys\n",
    "import cv2 as cv\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import playsound as ps\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "\n",
    "global ALARM_ON\n",
    "global ear\n",
    "\n",
    "# The function used in Face Detection to compute the ear,\n",
    "# through computing the ratio of distances between\n",
    "# the vertical eye landmarks and the distances between the horizontal eye landmarks\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    # compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "\n",
    "    # compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "\n",
    "    # compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "\n",
    "    # return the eye aspect ratio\n",
    "    return ear\n",
    "\n",
    "class Window(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"E-TOOL\")\n",
    "        self.setGeometry(350,100,700,500)\n",
    "        self.setWindowIcon(QIcon('Icon.png'))\n",
    "        self.mainMenu = QMenuBar()\n",
    "        self.setStyleSheet(\"\"\"\n",
    "              \n",
    "               QMenu {\n",
    "                   background-color: #260252;\n",
    "                   color: rgb(255,255,255);\n",
    "                   border: 1px solid #000;           \n",
    "               }\n",
    "               QMenu::item::selected {\n",
    "                   background-color: #260252;\n",
    "               }\n",
    "           \"\"\")\n",
    "        self.fileMenu = self.mainMenu.addMenu('&File')\n",
    "        self.fileMenu.addAction(QAction(\"Upload Video\", self))\n",
    "        self.fileMenu.addAction(QAction(\"Exit\", self))\n",
    "        self.fileMenu.addAction(QAction(\"Help \", self))\n",
    "        p = self.palette()\n",
    "        p.setColor(QPalette.Window,Qt.white)\n",
    "        self.setPalette(p)\n",
    "        self.init_ui()\n",
    "        self.show()\n",
    "\n",
    "    # To Create the widgets we need\n",
    "    def init_ui(self):\n",
    "\n",
    "        # Create a Media player object\n",
    "        self.mediaplayer = QMediaPlayer(None, QMediaPlayer.VideoSurface)\n",
    "\n",
    "        # Create Video widget object\n",
    "        videowidget = QVideoWidget()\n",
    "\n",
    "        # Face detection and drowsiness button\n",
    "        faceDetetction = QPushButton(\"Face Detection\")\n",
    "        faceDetetction.setStyleSheet(\"color: white; font-size: 16px; background-color: #260252;\" \"border-radius: 10px; padding: 10px; text-align: center; \")\n",
    "        faceDetetction.clicked.connect(self.FaceDetection)\n",
    "\n",
    "        # Create Open button\n",
    "        openBtn = QPushButton('Upload Video')\n",
    "        openBtn.clicked.connect(self.open_file)\n",
    "        openBtn.setStyleSheet(\"QPushButton::pressed\"\"{\"\"background-color : white;\"\"}\")\n",
    "        openBtn.setStyleSheet(\"color: white; font-size: 12px; background-color: #260252; border-radius: 10px;\"\" padding: 10px; text-align: center;\")\n",
    "\n",
    "        # Create an Information Label\n",
    "        self.label2 =QLabel()\n",
    "        self.label2.setStyleSheet(\"color:#260252 ; font-size: 12px; border-radius: 10px; padding:\"\" 10px; text-align: center;\")\n",
    "        self.label2.setSizePolicy(QSizePolicy.Preferred, QSizePolicy.Maximum)\n",
    "        self.label2.setText(\"To Exit Face Detection Press ESC\")\n",
    "\n",
    "        # Create Play button\n",
    "        self.playBtn=QPushButton()\n",
    "        self.playBtn.setEnabled(False)\n",
    "        self.playBtn.setIcon(QIcon(\"play.png\"))\n",
    "        self.playBtn.clicked.connect(self.play_video)\n",
    "        self.playBtn.setStyleSheet(\"color: black; font-size: 12px; background-color: #FF8C00;\"\" border-radius: 10px; padding: 10px; text-align: center;\")\n",
    "        self.playBtn.setStyleSheet(\"QPushButton::pressed\" \"{\" \"background-color : green;\"\"}\")\n",
    "        #self.playBtn.clicked.connect(self.FaceDetection)\n",
    "\n",
    "        # Create Stop button\n",
    "        self.stopBtn = QPushButton()\n",
    "        self.stopBtn.setEnabled(False)\n",
    "        self.stopBtn.setIcon(QIcon(\"replay.png\"))\n",
    "        self.stopBtn.setStyleSheet(\"QPushButton::pressed\"\"{\" \"background-color : red;\"\"}\" )\n",
    "        self.stopBtn.pressed.connect(self.stop_video)\n",
    "\n",
    "        self.label = QLabel()\n",
    "        self.label.setSizePolicy(QSizePolicy.Preferred, QSizePolicy.Maximum)\n",
    "\n",
    "        # Create Position slider\n",
    "        self.slider=QSlider(Qt.Horizontal)\n",
    "        self.slider.setRange(0, 0)\n",
    "        self.slider.sliderMoved.connect(self.set_position)\n",
    "\n",
    "        # Create volume label image\n",
    "        self.label1=QLabel()\n",
    "        self.label1.setText(\"\")\n",
    "        self.label1.setPixmap(QPixmap(\"speaker-volume\"))\n",
    "\n",
    "        # Create volume slider\n",
    "        self.volumeSlider = QSlider()\n",
    "        self.volumeSlider.setMaximum(100)\n",
    "        self.volumeSlider.setProperty(\"value\", 100)\n",
    "        self.volumeSlider.setOrientation(Qt.Horizontal)\n",
    "        self.volumeSlider.setObjectName(\"volumeSlider\")\n",
    "        self.volumeSlider.valueChanged.connect(self.mediaplayer.setVolume)\n",
    "        self.volumeSlider.setStyleSheet(\"border-color: :#260252;\")\n",
    "\n",
    "        #Adding a spacer item in the Hbox\n",
    "        spacer =QSpacerItem(20, 20, QSizePolicy.Expanding, QSizePolicy.Minimum)\n",
    "        spacerItem1 = QSpacerItem(40, 20, QSizePolicy.Expanding, QSizePolicy.Minimum)\n",
    "\n",
    "        # Create Hbox Layout\n",
    "        hboxlayout= QHBoxLayout()\n",
    "        hboxlayout.setContentsMargins(0, 0, 0, 0)\n",
    "\n",
    "        # Set Widgets to the hbox layout\n",
    "        hboxlayout.addWidget(openBtn)\n",
    "        hboxlayout.addWidget(self.playBtn)\n",
    "        hboxlayout.addWidget(self.stopBtn)\n",
    "        hboxlayout.addItem(spacer)\n",
    "        hboxlayout.addWidget(self.label1)\n",
    "        hboxlayout.addWidget(self.volumeSlider)\n",
    "\n",
    "\n",
    "        # Create vbox layout ( will be the main layout including the hbox layout)\n",
    "        vboxlayout=QVBoxLayout()\n",
    "        vboxlayout.addWidget(videowidget)\n",
    "        vboxlayout.addWidget(self.slider)\n",
    "        vboxlayout.addLayout(hboxlayout)\n",
    "        vboxlayout.addWidget(self.label2)\n",
    "        vboxlayout.addWidget(faceDetetction)\n",
    "\n",
    "        # Set the layout to your window\n",
    "        self.setLayout((vboxlayout))\n",
    "\n",
    "        # Get the video to output on the video widget window\n",
    "        self.mediaplayer.setVideoOutput(videowidget)\n",
    "\n",
    "        # Media player signals\n",
    "        self.mediaplayer.stateChanged.connect(self.mediastate_changed)\n",
    "        self.mediaplayer.positionChanged.connect(self.position_changed)\n",
    "        self.mediaplayer.durationChanged.connect(self.duration_changed)\n",
    "\n",
    "    # Choosing media file from your device\n",
    "    def open_file(self):\n",
    "        filename, _ = QFileDialog.getOpenFileName(self, \"Open file\", \"\", \"mp3 Audio (*.mp3);mp4 Video (*.mp4);\"\n",
    "                                                                         \"Movie files (*.mov);All files (*.*)\")\n",
    "\n",
    "        if filename != '':\n",
    "            self.mediaplayer.setMedia(QMediaContent(QUrl.fromLocalFile(filename)))\n",
    "            self.playBtn.setEnabled(True)\n",
    "        # Error handling in case wrong format media file is choosen\n",
    "        if not filename.endswith('.mp3') | filename.endswith('.mp4') | filename.endswith('.mov') | filename.endswith('.mkv')\\\n",
    "                | filename.endswith('.MP3') | filename.endswith('.MP4') | filename.endswith('.MOV') | filename.endswith('.MKV')\\\n",
    "                | filename.endswith('.wav') | filename.endswith('.WAV'):\n",
    "\n",
    "          # Create warning message box and it characteristics\n",
    "            self.playBtn.setEnabled(False)\n",
    "            msg1 = QMessageBox()\n",
    "            msg1.setWindowTitle(\"File Error !\")\n",
    "            msg1.setText(\"Invalid File Type\")\n",
    "            msg1.setIcon(QMessageBox.Warning)\n",
    "            msg1.setWindowIcon(QIcon('file error.png'))\n",
    "            msg1.setStandardButtons(QMessageBox.Retry | QMessageBox.Abort)\n",
    "            msg1.setStyleSheet('QMessageBox {background-color: #260252; color: white;padding: 40px;}\\n QMessageBox {color: white;}\\n ''QPushButton{color: white; font-size: 16px; background-color: #1d1d1d; '  'border-radius: 10px; padding: 20px; text-align: center;}\\n QPushButton:hover{color: #260252;}')\n",
    "            msg1.buttonClicked.connect(self.popup1)\n",
    "            y = msg1.exec_()\n",
    "\n",
    "    # pop up message if the user choose an invalid input type\n",
    "    def popup1(self, i):\n",
    "        # if the user choose retry he can can try again to choose a file of a valid format\n",
    "        if i.text() == 'Retry':\n",
    "            self.open_file()\n",
    "        # if the user chooses to abort then the window is closed\n",
    "        if i.text() == 'Abort':\n",
    "            cv.destroyAllWindows()\n",
    "\n",
    "    # Stoping the video and replay it agaian from the beginning\n",
    "    def stop_video(self):\n",
    "        self.mediaplayer.stop()\n",
    "        \n",
    "        self.playBtn.setIcon(QIcon('play.png'))\n",
    "\n",
    "    # Pressing play button while it's in pause state, Plays the video\n",
    "    #Pressing play button while it's in play state , Pauses the video\n",
    "    def play_video(self):\n",
    "        if self.mediaplayer.state()  == QMediaPlayer.PlayingState:\n",
    "            self.mediaplayer.pause()\n",
    "            self.stopBtn.setEnabled(True)\n",
    "            self.playBtn.setIcon(QIcon('play.png'))\n",
    "        else:\n",
    "            self.mediaplayer.play()\n",
    "            self.stopBtn.setEnabled(True)\n",
    "            self.playBtn.setIcon(QIcon('pause.png'))\n",
    "\n",
    "    # Linking mediaplayer state to play button\n",
    "    def mediastate_changed(self, state):\n",
    "        if self.mediaplayer.state() == QMediaPlayer.PlayingState:\n",
    "            self.playBtn.setIcon(QIcon('play.png'))\n",
    "        else:\n",
    "            self.playBtn.setIcon(QIcon('pause.png'))\n",
    "\n",
    "    # Changing slider position while video is playing\n",
    "    def position_changed(self, position):\n",
    "        self.slider.setValue(position)\n",
    "\n",
    "    # Changing slider duration range ehike the video is playing\n",
    "    def duration_changed(self, duration):\n",
    "        self.slider.setRange(0, duration)\n",
    "\n",
    "    def set_position(self, position):\n",
    "        self.mediaplayer.setPosition(position)\n",
    "\n",
    "    def handle_errors(self):\n",
    "        self.playBtn.setEnabled(False)\n",
    "        self.label.setText(\"Error: \" + self.mediaplayer.errorString())\n",
    "\n",
    "    # On clicking face detetction button this method is executed\n",
    "    def FaceDetection(self):\n",
    "\n",
    "        # Threshold ratio to indicate a blink\n",
    "        EYE_AR_THRESH = 0.2\n",
    "        # Number of frames threshold above which video is paused\n",
    "        EYE_AR_CONSEC_FRAMES = 30\n",
    "\n",
    "        # Initialize the frame counter as well as a boolean used to\n",
    "        # indicate if the alarm is going off\n",
    "        COUNTER = 0\n",
    "        ALARM_ON = False\n",
    "\n",
    "        # Initialize dlib's face detector (HOG-based) and then create\n",
    "        # the facial landmark predictor\n",
    "        detector = dlib.get_frontal_face_detector()\n",
    "        predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "        # Grab the indexes of the facial landmarks for the left and\n",
    "        # right eye, respectively\n",
    "        (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "        (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "        # Open the webcam and read the stream\n",
    "        cap = cv.VideoCapture(0)\n",
    "        # Use opencv cascade classifier in detecting the face\n",
    "        face_cascade = cv.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "        while True:\n",
    "            # get the frames from the webcam\n",
    "            ret, frame = cap.read()\n",
    "            # convert the frames from rgb into grey\n",
    "            frame_gray = cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\n",
    "            frame_gray = cv.equalizeHist(frame_gray)\n",
    "            # use the detector and get the rectangles from it\n",
    "            rects = detector(frame_gray, 0)\n",
    "\n",
    "            # -- Detect faces\n",
    "            faces = face_cascade.detectMultiScale(frame_gray, minSize=(85, 85))\n",
    "            # count the number of face in front of the cam\n",
    "            how_many_faces = len(faces)\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                # detect the center of the face\n",
    "                center = (x + w // 2, y + h // 2)\n",
    "                # draw an ellipse on the face\n",
    "                frame = cv.ellipse(frame, center, (w // 2, h // 2), 0, 0, 360, (255, 0, 255), 4)\n",
    "                faceROI = frame_gray[y:y + h, x:x + w]\n",
    "\n",
    "            for rect in rects:\n",
    "                # determine the facial landmarks for the face\n",
    "                shape = predictor(frame_gray, rect)\n",
    "                # convert the facial landmark from (x, y) coordinates to a numpy array\n",
    "                shape = face_utils.shape_to_np(shape)\n",
    "                # extract the left and right eye coordinates\n",
    "                leftEye = shape[lStart:lEnd]\n",
    "                rightEye = shape[rStart:rEnd]\n",
    "                # use the coordinates to compute the eye aspect ratio for both eyes\n",
    "                leftEAR = eye_aspect_ratio(leftEye)\n",
    "                rightEAR = eye_aspect_ratio(rightEye)\n",
    "\n",
    "                # average the eye aspect ratio together for both eyes\n",
    "                ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "                # compute the convex hull for the left and right eye\n",
    "                leftEyeHull = cv.convexHull(leftEye)\n",
    "                rightEyeHull = cv.convexHull(rightEye)\n",
    "                # draw contours around eyes\n",
    "                cv.drawContours(frame, [leftEyeHull], -1, (75, 50, 130), 1)\n",
    "                cv.drawContours(frame, [rightEyeHull], -1, (75, 50, 130), 1)\n",
    "\n",
    "                # check if the eye aspect ratio is below the threshold, if so increment the counter of frames\n",
    "                if ear < EYE_AR_THRESH:\n",
    "                    COUNTER += 1\n",
    "\n",
    "                    # if the eyes were closed for more than the number of frames threshold (30) then put the alarm on\n",
    "                    if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                        # if the alarm is not on, turn it on\n",
    "                        if not ALARM_ON:\n",
    "                            ALARM_ON = True\n",
    "\n",
    "                        # draw an alarm on the frame\n",
    "                        cv.putText(frame, \"Sleepy Eyes Detected\", (10, 30),\n",
    "                                   cv.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "                # if the ear is greater than the threshold then reset the counter of frames\n",
    "                else:\n",
    "                    COUNTER = 0\n",
    "                    ALARM_ON = False\n",
    "\n",
    "                # put the value of ear detected\n",
    "                cv.putText(frame, \"EAR: {:.2f}\".format(ear), (300, 30),\n",
    "                           cv.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "            # visualize the camera frame\n",
    "            cv.imshow('YOU ARE BEING WATCHED ', frame)\n",
    "\n",
    "            # if no faces are detected then pause\n",
    "            if how_many_faces == 0:\n",
    "                self.mediaplayer.pause()\n",
    "                self.mediaplayer.stateChanged\n",
    "                self.playBtn.setIcon(QIcon('play.png'))\n",
    "                self.mediaplayer.positionChanged.connect(self.position_changed)\n",
    "                self.mediaplayer.durationChanged.connect(self.duration_changed)\n",
    "\n",
    "            # if the alarm is on which means the ear is less than the threshold for 30 frames then pause\n",
    "            elif ALARM_ON:\n",
    "                self.mediaplayer.pause()\n",
    "                self.mediaplayer.stateChanged\n",
    "                self.playBtn.setIcon(QIcon('play.png'))\n",
    "                self.mediaplayer.positionChanged.connect(self.position_changed)\n",
    "                self.mediaplayer.durationChanged.connect(self.duration_changed)\n",
    "\n",
    "                cv.destroyWindow('YOU ARE BEING WATCHED ')\n",
    "                n=0\n",
    "                while(n<=5):\n",
    "                    ps.playsound(\"alert.mp3\")\n",
    "                    n+=1\n",
    "                #exec(open('gm.py').read())\n",
    "                import game\n",
    "                #x= msg.exec_()\n",
    "\n",
    "            # if not sleepy or the face is detected then continue playing\n",
    "            else:\n",
    "                self.mediaplayer.play()\n",
    "                self.mediaplayer.stateChanged\n",
    "                self.playBtn.setIcon(QIcon('pause.png'))\n",
    "\n",
    "            # if ESC button is hit, then the camera frame is closed and the user is back to manual control\n",
    "            if cv.waitKey(10) == 27:\n",
    "                cap.release()\n",
    "                cv.destroyWindow('YOU ARE BEING WATCHED ')\n",
    "                break\n",
    "\n",
    "\n",
    "# Initiate the application\n",
    "app = QApplication(sys.argv)\n",
    "app.setStyle(\"Fusion\")\n",
    "# Make an instance of the Window class\n",
    "window = Window()\n",
    "sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43770cec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
